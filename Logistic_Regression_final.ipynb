{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://statsmodels.sourceforge.net/stable/datasets/generated/fair.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from patsy import dmatrices\n",
    "from sklearn import metrics\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib as mpl\n",
    "print(\"python \" + sys.version)\n",
    "print(\"\")\n",
    "print(\"pandas \" + str(pd.__version__))\n",
    "print(\"numpy \" + np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = sm.datasets.fair.load_pandas().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some summary statistics.\n",
    "#misleading - [ explained towards the end. bottom line - exercise caution while interpreting summary stats ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#need to run this to see the figures. \n",
    "#%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "axes = pd.tools.plotting.scatter_matrix(df, alpha=0.2)\n",
    "plt.tight_layout()\n",
    "plt.savefig('scatter_matrix.png')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['affair_bool'] = (df.affairs > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['affairs'].hist(bins=20)\n",
    "xlabel('affairs')\n",
    "ylabel('number of women')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Exploring affairs vs marraige ratings : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rating_vs_target = pd.crosstab(df['rate_marriage'], df['affair_bool'])\n",
    "rating_vs_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_ratings = rating_vs_target.apply(sum)\n",
    "total_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rating_vs_target /= total_ratings\n",
    "rating_vs_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rating_vs_target.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusion - Women who rate their marriages higher have lesser number of affairs. Let use a model to verify our claim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#splitting the model into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#set the random state to get the same split each time\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_y = x_train[\"affair_bool\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_y = x_test[\"affair_bool\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = x_train.drop(\"affairs\", axis = 1, inplace = False)\n",
    "x_train = x_train.drop(\"affair_bool\", axis = 1, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_test = x_test.drop(\"affairs\", axis = 1, inplace = False)\n",
    "x_test = x_test.drop(\"affair_bool\", axis = 1, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logit = linear_model.LogisticRegression()\n",
    "logit.fit(x_train,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#making predictions. By default, 0.5 is chosen as the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = logit.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculating accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean((predicted - test_y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logit.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logit.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = pd.Series(logit.coef_[0],\n",
    "                 index= x_train.columns.values)\n",
    "weights.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusions - We observed from the bar graph that a higher marriage rating means a lower chance of having an affair. The negative coefficient value of rate_marriage variable - -0.683867 tells us exactly that. But are we on the right track?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We observe that the occupation husb and occupation columns are categorical columns. We need to make them categorical so we will use design matrices.\n",
    "# The C(occupation_husb) and C(occupation) is doing just that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y, X = dmatrices('affair_bool ~ rate_marriage + age + educ + children + C(occupation_husb) + C(occupation) + yrs_married', df, return_type = 'dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logit_categorical = linear_model.LogisticRegression(fit_intercept = False, C = 1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logit_categorical.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logit_categorical.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights_categories = pd.Series(logit_categorical.coef_[0],\n",
    "                 index= X.columns.values)\n",
    "weights_categories.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This makes more sense. Let's calculate the accuracy insample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logit_categorical.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's now check the out of sample test accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_logit_categorical = logit_categorical.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test, predicted_logit_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#getting the predicted probabilities.\n",
    "predicted_prob = logit_categorical.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How do we choose the cut off threshold? \n",
    "##### 1. Depends on the business problem\n",
    "##### 2. Related to 1 - How much error are we willing to make by predicting either class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_class_1 = [item[1] for item in predicted_prob]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predicted_class_1)\n",
    "roc_auc = metrics.auc(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#adapted from http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html#sphx-glr-auto-examples-model-selection-plot-roc-py\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('roc.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### REGULARIZATION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Switch to Emma\n",
    "\n",
    "What if the effect of husband's occupation depends on the wife's occupation, or the effect of children depends on years married? \n",
    "\n",
    "We can add features to include interaction terms. First let's have a look at what feature we have now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not want to create interaction terms with intercept because that will simply be the feature itself. Lets drop be intercept column first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train= X_train.drop('Intercept', axis=1)\n",
    "X_test= X_test.drop('Intercept', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X_train.shape \n",
    "print X_test.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the range of values is different for each numerical variables. Since the values of coefficience matter in regularization, we want to standardize the data first (only numerical variables). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in ['rate_marriage','age','educ','children','yrs_married']:\n",
    "    X_train[i]= (X_train[i] - X_train[i].mean()) / X_train[i].std()\n",
    "    X_test[i]= (X_test[i] - X_test[i].mean()) / X_test[i].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally we want to standardize training/testing data the same way. But considering after training the model one may not keep the original training data, we standardized the testing data with its own mean/std.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the current dataset has 15 features. With PolynomialFeatures, we can create all second order features in one command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(2)\n",
    "X_train_2 = poly.fit_transform(X_train)\n",
    "X_test_2 = poly.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X_train_2.shape \n",
    "print X_test_2.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is 1 feature for the intercept, 15 original features, 15 second order features for the original 15 features, and 15-choose-2(105) second order interacting features. The total number of features is 136 as expected.\n",
    "\n",
    "The outputs of PolynomialFeatures are numpy arrays. Let's add the column names back and make some dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_feature_names = poly.get_feature_names(X_train.columns.values)\n",
    "X_train_2_df = pd.DataFrame(X_train_2, columns = target_feature_names)\n",
    "X_test_2_df = pd.DataFrame(X_test_2, columns = target_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_2_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's fit a new logistic regression with our freshly made features :) For easy comparison, we use the same parameters as used in the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = linear_model.LogisticRegression(fit_intercept = False, penalty = 'l2', C= 1e9)\n",
    "model.fit(X_train_2_df,y_train)\n",
    "\n",
    "print 'train_score = ', model.score(X_train_2_df, y_train)\n",
    "    \n",
    "predicted = model.predict(X_test_2_df)\n",
    "print 'test_score = ', metrics.accuracy_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the most important features this time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights_categories = pd.Series(model.coef_[0],\n",
    "                 index= X_train_2_df.columns.values)\n",
    "topindices = np.argsort(-np.abs(model.coef_[0]))[:10]\n",
    "weights_categories[topindices][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The testing error is a bit larger than the training error. We may be overfitting the dataset. Why don't we try some regularization? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_order2(pen,reg):\n",
    "    model = linear_model.LogisticRegression(fit_intercept = False, penalty = pen, C= reg)\n",
    "    model.fit(X_train_2_df,y_train)\n",
    "    \n",
    "    #print model.coef_\n",
    "    train_score = model.score(X_train_2_df, y_train)\n",
    "    \n",
    "    predicted = model.predict(X_test_2_df)\n",
    "    test_score = metrics.accuracy_score(y_test, predicted)\n",
    "    \n",
    "    return train_score, test_score, model.coef_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a suite of models with various regularization strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "penalties = [1e9, 1e6, 1e4, 1e2, 10, 1, 1e-1, 1e-2, 1e-3, 1e-4]\n",
    "types = ['l1', 'l2']\n",
    "\n",
    "train_score = np.zeros([len(types),len(penalties)])\n",
    "test_score = np.zeros([len(types),len(penalties)])\n",
    "coeff = np.zeros([len(types),len(penalties),X_train_2_df.shape[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(types)):\n",
    "    for j in range(len(penalties)):\n",
    "        (train_score[i,j], test_score[i,j], coeff[i,j,:]) = fit_order2(types[i], penalties[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print train_score[0,:]\n",
    "print test_score[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the accuracy and coefficents change with the penalty. We want to plot the lambda instead of C for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual_pen = [1/i for i in penalties]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual_pen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = 12, 8\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot()\n",
    "ydata =[train_score[0,:], test_score[0,:], train_score[1,:], test_score[1,:]]\n",
    "colors =['red', 'black', 'red','black']\n",
    "markers = ['o','o','^','^']\n",
    "labels =[ 'L1 train','L1 test','L2 train','L2 test']\n",
    "for i in range(4):\n",
    "    ax.scatter(actual_pen,ydata[i], color= colors[i] ,label = labels[i],marker=markers[i], s=50)\n",
    "    ax.plot(actual_pen, ydata[i], color=colors[i])\n",
    "\n",
    "\n",
    "ax.set_xscale('log')\n",
    "plt.xlim([1e-9, 1e5])\n",
    "plt.xlabel('Lambda (penalty)', fontsize=25)\n",
    "plt.ylabel('Accuracy', fontsize=25)\n",
    "plt.legend(loc=3) #, fontsize=25\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's extract top 10 most important word for l2, week reguarlization\n",
    "l1indices = np.argsort(-np.abs(coeff[0,0,:]))[:10]\n",
    "l2indices = np.argsort(-np.abs(coeff[1,0,:]))[:10]\n",
    "#print indices\n",
    "l1coeff = coeff[0,:,l1indices]\n",
    "l2coeff = coeff[1,:,l2indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1words = weights_categories[l1indices].index\n",
    "l2words = weights_categories[l2indices].index\n",
    "print 'L1 regularization'\n",
    "print l1words\n",
    "print ''\n",
    "print 'L2 regularization'\n",
    "print l2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 16, 10\n",
    "\n",
    "def make_coefficient_plot(coeff, words, penalty_list, title):\n",
    "    \n",
    "    cmap = plt.get_cmap('Blues')\n",
    "    \n",
    "    xx = penalty_list\n",
    "    plt.plot(xx, [0.]*len(xx), '--', lw=1, color='k')\n",
    "    \n",
    "    table_words = coeff\n",
    "\n",
    "    for i in xrange(len(words)):\n",
    "        color = cmap(0.8*((i+1)/(len(words)*1.2)+0.15))\n",
    "        plt.plot(xx, coeff[i:i+1].flatten(),\n",
    "                 '-', label=words[i], linewidth=4.0, color=color)\n",
    "        \n",
    "    plt.legend(loc=1, ncol=2, prop={'size':16}, columnspacing=0.5)\n",
    "    plt.axis([1, 1e4, -1, 2])\n",
    "    #plt.ylim([-0.5,0.5])\n",
    "    plt.xlim([1, 1e4])\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Lambda (penalty)')\n",
    "    plt.ylabel('Coefficient value')\n",
    "    plt.xscale('log')\n",
    "\n",
    "    plt.rcParams.update({'font.size': 25})\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_coefficient_plot(l1coeff, l1words, actual_pen, 'L1 penalty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_coefficient_plot(l2coeff, l2words, actual_pen, 'L2 penalty')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caveats:\n",
    "There are only ~6k data points in this dataset, so the difference in training/testing error could just be noise.\n",
    "\n",
    "We will do better by doing cross-validation, but it's hard to gain much just because we don't have much data to start with."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
